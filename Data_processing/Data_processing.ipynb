{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data processing steps:\n",
    "\n",
    "1.importing libraries\n",
    "\n",
    "2.Getting dataset\n",
    "\n",
    "3.importing datasets\n",
    "\n",
    "4.finding missing values\n",
    "\n",
    "5.Encoding Catrgorical data\n",
    "\n",
    "6.Splitting dataset into Training & Test set\n",
    "\n",
    "7.Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing datasets\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "আমাদের এখানে .values use করা লাগসে কারণ যদি use না করি তাহলে excel এর মতো আসবে \n",
    "কিন্তু আমাদের array লাগবে তাই .values use করা লাগবে"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset.iloc[:,:-1].values  #Independent variables\n",
    "y=dataset.iloc[:,-1].values   #Dependent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding missing values\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "impute use করা হয় যাতে missing value কে replace করা যায়।\n",
    "\n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy=\"mean\") => missing value identify and replace.এখানে np.nan use করসি কারণ আমরা array নিয়ে কাজ করতেসি।\n",
    "\n",
    "imputer.fit(x[:,1:3])=> বাকি independent variable এর data load করা or Fit করা।\n",
    "\n",
    "x[:,1:3]=imputer.transform(x[:,1:3])=> independent variable এর array এর মধ্যে missing value গুলা transform or replace হয়ে যায়।Also we can transform numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy=\"mean\")\n",
    "imputer.fit(x[:,1:3])\n",
    "x[:,1:3]=imputer.transform(x[:,1:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Catagorical Data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding important কারণ আমাদের dataset মধ্যে correlation build up করার জন্য আমাদের সব data numeric করতে হবে।\n",
    "যার জন্য আমরা LabelEncoder and OneHotEncoder use করসি।\n",
    "\n",
    "\n",
    "OneHotEndcoder=> এটা তখনি use করি যখন Number of data in one column is greater than two like Country.There are 3 data=>Germany,France,spain.\n",
    "এখন যদি আমরা এদের 1,2,3 দিয়ে mark করি তাহলে model correlation e  problem করতে পারে।\n",
    "\n",
    "তাই আমরা dummy encoding use করব।\n",
    "like:\n",
    "\n",
    "                                                              Germany      france        spain\n",
    "                                                              ------       ------        -----\n",
    "                                          france               0              1            0\n",
    "                                          spain                0              0            1\n",
    "                                          Germany              1              0            0\n",
    "                                          Spain                0              0            1\n",
    "                                          Germany              1              0            0\n",
    "\n",
    "এতে করে correlation এর problem হয় না।\n",
    "\n",
    "***LabelEncoding=> যদি 2 টা data থাকে then এটা করলে enough only 0,1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder='passthrough')\n",
    "\n",
    "#ct=OneHotEncoder.fit_transform(dataset.Country.values.reshape(-1,1).toarray())=>এটা দিয়েও একই কাজ হয়।\n",
    "\n",
    "X=np.array(ct.fit_transform(x))\n",
    "le=LabelEncoder()\n",
    "Y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset into Training & Test set\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "আমরা যে data দিয়ে কাজ করতেসি যদি সেই data দিয়ে test করি কেমন কাজ করতেসে তাহলে ত 100% accuracy দিবে।\n",
    "তাই আমাদের অন্য data দিয়ে কাজ করতে হবে।যার জন্য আমরা আমাদের dataset কে Test data and train data দুই ভাগে ভাগ করি।\n",
    "train data দিয়ে train করি and test data দিয়ে test করি।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc=StandardScaler()\n",
    "X_train[:,3:]=sc.fit_transform(X_train[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
